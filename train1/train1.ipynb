{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用CNN 进行训练 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# print(1)\n",
    "\n",
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   image_name  width  height  xmin  ymin  xmax  ymax\n",
      "0    0001.jpg   1956    1934   631   903   839  1121\n",
      "1    0002.jpg   1956    1934   653   901   883  1131\n",
      "2    0003.jpg   2992    2000  1368   939  1570  1137\n",
      "3    0004.jpg   2992    2000  1560  1006  1757  1202\n",
      "4    0005.jpg   2992    2000  1637  1016  1826  1202\n",
      "..        ...    ...     ...   ...   ...   ...   ...\n",
      "75   0076.jpg   2992    2000  1407   933  1582  1106\n",
      "76   0077.jpg   2992    2000  1203   837  1399  1037\n",
      "77   0078.jpg   2992    2000  1570  1006  1766  1199\n",
      "78   0079.jpg   2992    2000  1187  1037  1355  1222\n",
      "79   0080.jpg   2992    2000  1364   943  1549  1118\n",
      "\n",
      "[80 rows x 7 columns]\n",
      "   image_name  width  height      xmin      ymin      xmax      ymax\n",
      "0    0001.jpg   1956    1934  0.322597  0.466908  0.428937  0.579628\n",
      "1    0002.jpg   1956    1934  0.333845  0.465874  0.451431  0.584798\n",
      "2    0003.jpg   2992    2000  0.457219  0.469500  0.524733  0.568500\n",
      "3    0004.jpg   2992    2000  0.521390  0.503000  0.587233  0.601000\n",
      "4    0005.jpg   2992    2000  0.547126  0.508000  0.610294  0.601000\n",
      "..        ...    ...     ...       ...       ...       ...       ...\n",
      "75   0076.jpg   2992    2000  0.470254  0.466500  0.528743  0.553000\n",
      "76   0077.jpg   2992    2000  0.402072  0.418500  0.467580  0.518500\n",
      "77   0078.jpg   2992    2000  0.524733  0.503000  0.590241  0.599500\n",
      "78   0079.jpg   2992    2000  0.396725  0.518500  0.452874  0.611000\n",
      "79   0080.jpg   2992    2000  0.455882  0.471500  0.517714  0.559000\n",
      "\n",
      "[80 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import uniform\n",
    "import csv\n",
    "from skimage.feature import hog\n",
    "import os\n",
    "import xmltodict\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def parse_xml_to_dataframe(xml_folder):\n",
    "    data = []\n",
    "    \n",
    "    # 遍历 XML 文件夹中的每个文件\n",
    "    for xml_file in os.listdir(xml_folder):\n",
    "        if xml_file.endswith('.xml'):\n",
    "            with open(os.path.join(xml_folder, xml_file), 'r') as file:\n",
    "                xml_data = xmltodict.parse(file.read())\n",
    "            \n",
    "            # 提取关键信息\n",
    "            annotation = xml_data['annotation']\n",
    "            filename = annotation['filename']\n",
    "            size = annotation['size']\n",
    "            objects = annotation['object']\n",
    "            \n",
    "            # 提取图像尺寸\n",
    "            width = int(size['width'])\n",
    "            height = int(size['height'])\n",
    "            \n",
    "            # 如果存在多个对象，需要处理成列表\n",
    "            if isinstance(objects, list):\n",
    "                for obj in objects:\n",
    "                    bndbox = obj['bndbox']\n",
    "                    data.append({\n",
    "                        'image_name': filename,\n",
    "                        'width': width,\n",
    "                        'height': height,\n",
    "                        'xmin': int(bndbox['xmin']),\n",
    "                        'ymin': int(bndbox['ymin']),\n",
    "                        'xmax': int(bndbox['xmax']),\n",
    "                        'ymax': int(bndbox['ymax'])\n",
    "                    })\n",
    "            else:\n",
    "                bndbox = objects['bndbox']\n",
    "                data.append({\n",
    "                    'image_name': filename,\n",
    "                    'width': width,\n",
    "                    'height': height,\n",
    "                    'xmin': int(bndbox['xmin']),\n",
    "                    'ymin': int(bndbox['ymin']),\n",
    "                    'xmax': int(bndbox['xmax']),\n",
    "                    'ymax': int(bndbox['ymax'])\n",
    "                })\n",
    "\n",
    "    # 转换为 Pandas DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# 调用函数解析 XML 数据\n",
    "xml_folder = 'C:/code/vcpython/ML_design_1/task1/detection/train_location'  # 替换为实际路径\n",
    "train_location_df = parse_xml_to_dataframe(xml_folder)\n",
    "print(train_location_df)\n",
    "\n",
    "\n",
    "def normalize_coordinates(df):\n",
    "    df['xmin'] = df['xmin'] / df['width']\n",
    "    df['ymin'] = df['ymin'] / df['height']\n",
    "    df['xmax'] = df['xmax'] / df['width']\n",
    "    df['ymax'] = df['ymax'] / df['height']\n",
    "    return df\n",
    "\n",
    "# 对边框数据归一化\n",
    "train_location_df = normalize_coordinates(train_location_df)\n",
    "print(train_location_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用SVM回归预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import uniform\n",
    "import csv\n",
    "from skimage.feature import hog\n",
    "import os\n",
    "import xmltodict\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2、读取数据,处理xml文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   image_name  width  height  xmin  ymin  xmax  ymax\n",
      "0    0001.jpg   1956    1934   631   903   839  1121\n",
      "1    0002.jpg   1956    1934   653   901   883  1131\n",
      "2    0003.jpg   2992    2000  1368   939  1570  1137\n",
      "3    0004.jpg   2992    2000  1560  1006  1757  1202\n",
      "4    0005.jpg   2992    2000  1637  1016  1826  1202\n",
      "..        ...    ...     ...   ...   ...   ...   ...\n",
      "75   0076.jpg   2992    2000  1407   933  1582  1106\n",
      "76   0077.jpg   2992    2000  1203   837  1399  1037\n",
      "77   0078.jpg   2992    2000  1570  1006  1766  1199\n",
      "78   0079.jpg   2992    2000  1187  1037  1355  1222\n",
      "79   0080.jpg   2992    2000  1364   943  1549  1118\n",
      "\n",
      "[80 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "def parse_xml_to_dataframe(xml_folder):\n",
    "    data = []\n",
    "    \n",
    "    # 遍历 XML 文件夹中的每个文件\n",
    "    for xml_file in os.listdir(xml_folder):\n",
    "        if xml_file.endswith('.xml'):\n",
    "            with open(os.path.join(xml_folder, xml_file), 'r') as file:\n",
    "                xml_data = xmltodict.parse(file.read())\n",
    "            \n",
    "            # 提取关键信息\n",
    "            annotation = xml_data['annotation']\n",
    "            filename = annotation['filename']\n",
    "            size = annotation['size']\n",
    "            objects = annotation['object']\n",
    "            \n",
    "            # 提取图像尺寸\n",
    "            width = int(size['width'])\n",
    "            height = int(size['height'])\n",
    "            \n",
    "            # 如果存在多个对象，需要处理成列表\n",
    "            if isinstance(objects, list):\n",
    "                for obj in objects:\n",
    "                    bndbox = obj['bndbox']\n",
    "                    data.append({\n",
    "                        'image_name': filename,\n",
    "                        'width': width,\n",
    "                        'height': height,\n",
    "                        'xmin': int(bndbox['xmin']),\n",
    "                        'ymin': int(bndbox['ymin']),\n",
    "                        'xmax': int(bndbox['xmax']),\n",
    "                        'ymax': int(bndbox['ymax'])\n",
    "                    })\n",
    "            else:\n",
    "                bndbox = objects['bndbox']\n",
    "                data.append({\n",
    "                    'image_name': filename,\n",
    "                    'width': width,\n",
    "                    'height': height,\n",
    "                    'xmin': int(bndbox['xmin']),\n",
    "                    'ymin': int(bndbox['ymin']),\n",
    "                    'xmax': int(bndbox['xmax']),\n",
    "                    'ymax': int(bndbox['ymax'])\n",
    "                })\n",
    "\n",
    "    # 转换为 Pandas DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# 调用函数解析 XML 数据\n",
    "xml_folder = 'C:/code/vcpython/ML_design_1/task1/detection/train_location'  # 替换为实际路径\n",
    "train_location_df = parse_xml_to_dataframe(xml_folder)\n",
    "print(train_location_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3、边框数据归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   image_name  width  height      xmin      ymin      xmax      ymax\n",
      "0    0001.jpg   1956    1934  0.322597  0.466908  0.428937  0.579628\n",
      "1    0002.jpg   1956    1934  0.333845  0.465874  0.451431  0.584798\n",
      "2    0003.jpg   2992    2000  0.457219  0.469500  0.524733  0.568500\n",
      "3    0004.jpg   2992    2000  0.521390  0.503000  0.587233  0.601000\n",
      "4    0005.jpg   2992    2000  0.547126  0.508000  0.610294  0.601000\n",
      "..        ...    ...     ...       ...       ...       ...       ...\n",
      "75   0076.jpg   2992    2000  0.470254  0.466500  0.528743  0.553000\n",
      "76   0077.jpg   2992    2000  0.402072  0.418500  0.467580  0.518500\n",
      "77   0078.jpg   2992    2000  0.524733  0.503000  0.590241  0.599500\n",
      "78   0079.jpg   2992    2000  0.396725  0.518500  0.452874  0.611000\n",
      "79   0080.jpg   2992    2000  0.455882  0.471500  0.517714  0.559000\n",
      "\n",
      "[80 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "def normalize_coordinates(df):\n",
    "    df['xmin'] = df['xmin'] / df['width']\n",
    "    df['ymin'] = df['ymin'] / df['height']\n",
    "    df['xmax'] = df['xmax'] / df['width']\n",
    "    df['ymax'] = df['ymax'] / df['height']\n",
    "    return df\n",
    "\n",
    "# 对边框数据归一化\n",
    "train_location_df = normalize_coordinates(train_location_df)\n",
    "print(train_location_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4、整合信息，将csv文件整合到边框中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown format code 'd' for object of type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;66;03m# print(i)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m---> 11\u001b[0m fovea_gt_copy \u001b[38;5;241m=\u001b[39m \u001b[43mformat_fovea_gt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfovea_gt_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# print(fovea_gt_copy)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m fovea_gt_copy\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/code/vcpython/ML_design_1/task1/detection/fovea_localization_train_GT_copy.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[33], line 7\u001b[0m, in \u001b[0;36mformat_fovea_gt\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_fovea_gt\u001b[39m(df):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_name\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m----> 7\u001b[0m         df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_name\u001b[39m\u001b[38;5;124m'\u001b[39m][i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m04d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;66;03m# print(i)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown format code 'd' for object of type 'str'"
     ]
    }
   ],
   "source": [
    "#格式化fovea_localization_train_GT.csv文件\n",
    "fovea_gt_copy = pd.read_csv('C:/code/vcpython/ML_design_1/task1/detection/fovea_localization_train_GT_copy.csv')\n",
    "\n",
    "def format_fovea_gt(df):\n",
    "    for i in df['image_name']:\n",
    "        df['image_name'][i - 1] = f'{i:04d}.jpg'\n",
    "        # print(i)\n",
    "    return df\n",
    "\n",
    "fovea_gt_copy = format_fovea_gt(fovea_gt_copy)\n",
    "# print(fovea_gt_copy)\n",
    "\n",
    "fovea_gt_copy.to_csv('C:/code/vcpython/ML_design_1/task1/detection/fovea_localization_train_GT_copy.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5、对黄斑区域数据进行预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.0026468136589358005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['svm_regressor_ymax.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skimage.feature import hog\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# 提取图像的 HOG 特征\n",
    "def extract_hog_features(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # 转为灰度图\n",
    "    img = cv2.resize(img, (256, 256))  # 调整图像大小\n",
    "    features, _ = hog(img, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)\n",
    "    return features\n",
    "\n",
    "# 颜色直方图特征提取\n",
    "def extract_color_histogram(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)  # 转换到HSV空间\n",
    "    hist = cv2.calcHist([image], [0, 1, 2], None, [16, 16, 16], [0, 180, 0, 256, 0, 256])  # 计算直方图\n",
    "    return hist.flatten()  # 扁平化直方图\n",
    "\n",
    "# 综合特征提取（HOG + 颜色直方图）\n",
    "def extract_features(image_path):\n",
    "    hog_features = extract_hog_features(image_path)\n",
    "    color_hist_features = extract_color_histogram(image_path)\n",
    "    # 合并HOG特征和颜色直方图特征\n",
    "    features = np.concatenate([hog_features, color_hist_features])\n",
    "    return features\n",
    "\n",
    "# 准备数据\n",
    "def prepare_data(df, image_folder):\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        # 获取图像路径和黄斑区域坐标\n",
    "        image_path = os.path.join(image_folder, row['image_name'])\n",
    "        xmin, ymin, xmax, ymax = row['xmin'], row['ymin'], row['xmax'], row['ymax']\n",
    "        \n",
    "        # 提取 HOG 特征\n",
    "        # feature = extract_hog_features(image_path)\n",
    "        feature = extract_features(image_path)\n",
    "        \n",
    "        # 将归一化坐标作为目标值\n",
    "        labels.append([xmin, ymin, xmax, ymax])\n",
    "        features.append(feature)\n",
    "    \n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# 加载数据\n",
    "image_folder = 'C:/code/vcpython/ML_design_1/task1/detection/train'  # 图像文件夹路径\n",
    "X, y = prepare_data(train_location_df, image_folder)\n",
    "\n",
    "# 切分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 使用标准化管道\n",
    "svm_regressor_xmin = make_pipeline(StandardScaler(), SVR(kernel='poly', C=0.03, gamma=0.01))\n",
    "svm_regressor_ymin = make_pipeline(StandardScaler(), SVR(kernel='poly', C=0.03, gamma=0.01))\n",
    "svm_regressor_xmax = make_pipeline(StandardScaler(), SVR(kernel='poly', C=0.03, gamma=0.01))\n",
    "svm_regressor_ymax = make_pipeline(StandardScaler(), SVR(kernel='poly', C=0.03, gamma=0.01))\n",
    "\n",
    "# 训练模型\n",
    "svm_regressor_xmin.fit(X_train, y_train[:, 0])\n",
    "svm_regressor_ymin.fit(X_train, y_train[:, 1])\n",
    "svm_regressor_xmax.fit(X_train, y_train[:, 2])\n",
    "svm_regressor_ymax.fit(X_train, y_train[:, 3])\n",
    "\n",
    "# 预测\n",
    "y_pred_xmin = svm_regressor_xmin.predict(X_test)\n",
    "y_pred_ymin = svm_regressor_ymin.predict(X_test)\n",
    "y_pred_xmax = svm_regressor_xmax.predict(X_test)\n",
    "y_pred_ymax = svm_regressor_ymax.predict(X_test)\n",
    "\n",
    "# 合并预测结果\n",
    "y_pred = np.stack((y_pred_xmin, y_pred_ymin, y_pred_xmax, y_pred_ymax), axis=1)\n",
    "\n",
    "# 计算误差\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# 你也可以保存模型以便后续使用\n",
    "import joblib\n",
    "joblib.dump(svm_regressor_xmin, 'svm_regressor_xmin.pkl')\n",
    "joblib.dump(svm_regressor_ymin, 'svm_regressor_ymin.pkl')\n",
    "joblib.dump(svm_regressor_xmax, 'svm_regressor_xmax.pkl')\n",
    "joblib.dump(svm_regressor_ymax, 'svm_regressor_ymax.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6、绘制黄斑框"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features for C:/code/vcpython/ML_design_1/task1/detection/test/0084.jpg: [0.16432005 0.         0.         0.         0.21909341]\n",
      "[0.44986109] [0.4815] [0.51351049] [0.57725]\n",
      "Predicted Bounding Box: xmin=[0.44986109], ymin=[0.4815], xmax=[0.51351049], ymax=[0.57725]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_20432\\861214221.py:73: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cv2.rectangle(image, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 255, 0), 2)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "\n",
    "# 提取图像的 HOG 特征\n",
    "def extract_hog_features(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # 转为灰度图\n",
    "    img = cv2.resize(img, (256, 256))  # 调整图像大小\n",
    "    features, _ = hog(img, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)\n",
    "    return features\n",
    "\n",
    "# 颜色直方图特征提取\n",
    "def extract_color_histogram(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)  # 转换到HSV空间\n",
    "    hist = cv2.calcHist([image], [0, 1, 2], None, [16, 16, 16], [0, 180, 0, 256, 0, 256])  # 计算直方图\n",
    "    return hist.flatten()  # 扁平化直方图\n",
    "\n",
    "# 综合特征提取（HOG + 颜色直方图）\n",
    "def extract_features(image_path):\n",
    "    hog_features = extract_hog_features(image_path)\n",
    "    color_hist_features = extract_color_histogram(image_path)\n",
    "    # 合并HOG特征和颜色直方图特征\n",
    "    features = np.concatenate([hog_features, color_hist_features])\n",
    "    print(f\"Extracted features for {image_path}: {features[:5]}\")  # 打印前5个特征值\n",
    "    return features\n",
    "\n",
    "svm_regressor_xmax = joblib.load('svm_regressor_xmax.pkl')\n",
    "svm_regressor_xmin = joblib.load('svm_regressor_xmin.pkl')\n",
    "svm_regressor_ymax = joblib.load('svm_regressor_ymax.pkl')\n",
    "svm_regressor_ymin = joblib.load('svm_regressor_ymin.pkl')\n",
    "\n",
    "# 预测函数\n",
    "def predict_bounding_box(image_path):\n",
    "    # 提取 HOG 特征\n",
    "    feature = extract_features(image_path)\n",
    "    \n",
    "    # 使用回归器分别预测四个坐标\n",
    "    xmin = svm_regressor_xmin.predict([feature])\n",
    "    ymin = svm_regressor_ymin.predict([feature])\n",
    "    xmax = svm_regressor_xmax.predict([feature])\n",
    "    ymax = svm_regressor_ymax.predict([feature])\n",
    "    \n",
    "    print(xmin, ymin, xmax, ymax)\n",
    "    # 返回预测的黄斑区域坐标\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "# 测试预测\n",
    "image_path = 'C:/code/vcpython/ML_design_1/task1/detection/test/0084.jpg'  # 替换为实际图像路径\n",
    "xmin, ymin, xmax, ymax = predict_bounding_box(image_path)\n",
    "\n",
    "# 打印预测的坐标\n",
    "print(f'Predicted Bounding Box: xmin={xmin}, ymin={ymin}, xmax={xmax}, ymax={ymax}')\n",
    "\n",
    "# 读取图像并调整大小\n",
    "image = cv2.imread(image_path)\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "# xmin = 1378\n",
    "# ymin = 941\n",
    "# xmax = 1585\n",
    "# ymax = 1149\n",
    "\n",
    "# 将坐标恢复到原图的尺寸\n",
    "xmin *= width\n",
    "ymin *= height\n",
    "xmax *= width\n",
    "ymax *= height\n",
    "\n",
    "# print(xmin, ymin, xmax, ymax, width, height)\n",
    "\n",
    "# 绘制预测框\n",
    "cv2.rectangle(image, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 255, 0), 2)\n",
    "\n",
    "# 调整显示图像的大小\n",
    "max_width = 1200  # 最大显示宽度\n",
    "max_height = 800  # 最大显示高度\n",
    "\n",
    "# 获取当前图像的宽度和高度\n",
    "h, w = image.shape[:2]\n",
    "\n",
    "# 计算缩放比例\n",
    "scale_width = max_width / w\n",
    "scale_height = max_height / h\n",
    "scale = min(scale_width, scale_height)\n",
    "\n",
    "# 调整图像大小\n",
    "new_dim = (int(w * scale), int(h * scale))\n",
    "resized_image = cv2.resize(image, new_dim)\n",
    "\n",
    "# 显示图像\n",
    "cv2.imshow('Predicted Bounding Box', resized_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   image_name  width  height      xmin      ymin      xmax      ymax  \\\n",
      "0    0001.jpg   1956    1934  0.322597  0.466908  0.428937  0.579628   \n",
      "1    0002.jpg   1956    1934  0.333845  0.465874  0.451431  0.584798   \n",
      "2    0003.jpg   2992    2000  0.457219  0.469500  0.524733  0.568500   \n",
      "3    0004.jpg   2992    2000  0.521390  0.503000  0.587233  0.601000   \n",
      "4    0005.jpg   2992    2000  0.547126  0.508000  0.610294  0.601000   \n",
      "..        ...    ...     ...       ...       ...       ...       ...   \n",
      "75   0076.jpg   2992    2000  0.470254  0.466500  0.528743  0.553000   \n",
      "76   0077.jpg   2992    2000  0.402072  0.418500  0.467580  0.518500   \n",
      "77   0078.jpg   2992    2000  0.524733  0.503000  0.590241  0.599500   \n",
      "78   0079.jpg   2992    2000  0.396725  0.518500  0.452874  0.611000   \n",
      "79   0080.jpg   2992    2000  0.455882  0.471500  0.517714  0.559000   \n",
      "\n",
      "        Fovea_X      Fovea_Y  \n",
      "0    734.031331  1016.817066  \n",
      "1    769.024859  1018.059762  \n",
      "2   1470.287475  1037.601074  \n",
      "3   1658.316671  1104.020062  \n",
      "4   1729.828431  1107.209978  \n",
      "..          ...          ...  \n",
      "75  1494.938977  1017.492746  \n",
      "76  1299.490121   934.244593  \n",
      "77  1665.401957  1101.482670  \n",
      "78  1270.251821  1134.462757  \n",
      "79  1457.479958  1033.677183  \n",
      "\n",
      "[80 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# 加载中心凹坐标\n",
    "fovea_gt = pd.read_csv('C:/code/vcpython/ML_design_1/task1/detection/fovea_localization_train_GT_copy.csv')\n",
    "# print(fovea_gt.columns)\n",
    "\n",
    "# 确保列名一致\n",
    "# fovea_gt.rename(columns={'image_name': 'image_name'}, inplace=True)\n",
    "\n",
    "# 归一化中心凹坐标\n",
    "# fovea_gt['Fovea_X'] = fovea_gt['Fovea_X'] / train_location_df['width']  # 假设宽度和图像相同\n",
    "# fovea_gt['Fovea_Y'] = fovea_gt['Fovea_Y'] / train_location_df['height']\n",
    "\n",
    "# print(fovea_gt)\n",
    "\n",
    "# 合并边框数据和中心凹坐标\n",
    "train_data = pd.merge(train_location_df, fovea_gt, on='image_name')\n",
    "print(train_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5、存储清洗过后的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('cleaned_train_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6、使用SVM进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 0.46875\n",
      "Mean Squared Error for fovea_x: 23935.13774945755\n",
      "Mean Squared Error for fovea_y: 1909.9304253350995\n",
      "Predicted fovea coordinates: (1469.5253168020552, 1047.6424107564362)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "# 读取数据\n",
    "data = pd.read_csv('cleaned_train_data.csv', header=None)\n",
    "data.columns = ['image_name', 'width', 'height', 'x1', 'y1', 'x2', 'y2', 'fovea_x', 'fovea_y']\n",
    "\n",
    "# 添加一个标签列，假设中心凹的框是由x1, y1, x2, y2定义的\n",
    "data['label'] = 1  # 假设所有数据都是中心凹的框\n",
    "\n",
    "# 特征和目标变量\n",
    "X = data[['width', 'height', 'x1', 'y1', 'x2', 'y2']]\n",
    "y_class = data['label']\n",
    "y_reg = data[['fovea_x', 'fovea_y']]\n",
    "\n",
    "# 分割数据集\n",
    "X_train, X_test, y_class_train, y_class_test, y_reg_train, y_reg_test = train_test_split(X, y_class, y_reg, test_size=0.2, random_state=42)\n",
    "\n",
    "# 训练SVM分类模型\n",
    "svc = SVC(kernel='rbf')\n",
    "svc.fit(X_train, y_class_train)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
